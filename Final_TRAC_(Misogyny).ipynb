{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final TRAC (Misogyny)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeInYBShv3gKcOvCqQNax1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guptatushar2000/Trolling-Aggression-and-Misogyny-Identification/blob/master/Final_TRAC_(Misogyny).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oARw1wmOJ_VV",
        "colab_type": "text"
      },
      "source": [
        "DATA ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYJjsQ5P95FH",
        "colab_type": "code",
        "outputId": "1229fe07-f905-4c04-d66c-85b171754709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCqOwEKpKVoC",
        "colab_type": "code",
        "outputId": "1f9ee15d-b817-4d62-cbcd-03fc902dc057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "plt.style.use('ggplot')\n",
        "stop=set(stopwords.words('english'))\n",
        "\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "import string\n",
        "\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM,Dense, SpatialDropout1D, Dropout\n",
        "from keras.initializers import Constant\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfPUEXSjKgkL",
        "colab_type": "code",
        "outputId": "ebba09b6-a067-41ed-a075-007f0f04840d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "tweet = pd.read_csv('/gdrive/My Drive/eng/eng/trac2_eng_train.csv')\n",
        "test = pd.read_csv('/gdrive/My Drive/trac2_eng_dev.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-77f5013fdd74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gdrive/My Drive/eng/eng/trac2_eng_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gdrive/My Drive/trac2_eng_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq5j9Tf7Kvot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('There are {} rows and {} columns in train'.format(tweet.shape[0],tweet.shape[1]))\n",
        "print('There are {} rows and {} columns in train'.format(test.shape[0],test.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C00llIR2K-Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO85a7jVLGKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet[\"Sub-task B\"] = tweet[\"Sub-task B\"].map({\"GEN\": 1, \"NGEN\": 0}).astype('int64')\n",
        "test[\"Sub-task B\"] = test[\"Sub-task B\"].map({\"GEN\": 1, \"NGEN\": 0}).astype('int64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itLWV2CPLNEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Miso_len = tweet[tweet['Sub-task B'] == 1].shape[0]\n",
        "Not_len = tweet[tweet['Sub-task B'] == 0].shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOIRqy5fLRKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (7, 5)\n",
        "plt.bar(10,Miso_len,3, label=\"Miso\", color='red')\n",
        "plt.bar(15,Not_len,3, label=\"Not\", color='blue')\n",
        "plt.legend()\n",
        "plt.ylabel('Number of examples')\n",
        "plt.title('Propertion of examples')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MASw9RQMLY3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def length(text):    \n",
        "    return len(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzPLnSjvLetT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet['length'] = tweet['Text'].apply(length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUVwpucJLj4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (18.0, 6.0)\n",
        "bins = 150\n",
        "plt.hist(tweet[tweet['Sub-task B'] == 0]['length'], alpha = 0.6, bins=bins, label='Not')\n",
        "plt.hist(tweet[tweet['Sub-task B'] == 1]['length'], alpha = 0.8, bins=bins, label='Miso')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('numbers')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlim(0,150)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_f3Pum3LsB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
        "tweet_len=tweet[tweet['Sub-task B']==1]['Text'].str.len()\n",
        "ax1.hist(tweet_len,color='red')\n",
        "ax1.set_title('miso tweets')\n",
        "tweet_len=tweet[tweet['Sub-task B']==0]['Text'].str.len()\n",
        "ax2.hist(tweet_len,color='Blue')\n",
        "ax2.set_title('Not miso tweets')\n",
        "fig.suptitle('Characters in tweets')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHV8NHuLyo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
        "tweet_len=tweet[tweet['Sub-task B']==1]['Text'].str.split().map(lambda x: len(x))\n",
        "ax1.hist(tweet_len,color='red')\n",
        "ax1.set_title('miso tweets')\n",
        "tweet_len=tweet[tweet['Sub-task B']==0]['Text'].str.split().map(lambda x: len(x))\n",
        "ax2.hist(tweet_len,color='blue')\n",
        "ax2.set_title('Not miso tweets')\n",
        "fig.suptitle('Words in a tweet')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QXZQu_1O6K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
        "word=tweet[tweet['Sub-task B']==1]['Text'].str.split().apply(lambda x : [len(i) for i in x])\n",
        "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\n",
        "ax1.set_title('miso')\n",
        "word=tweet[tweet['Sub-task B']==0]['Text'].str.split().apply(lambda x : [len(i) for i in x])\n",
        "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='blue')\n",
        "ax2.set_title('Not miso')\n",
        "fig.suptitle('Average word length in each tweet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pET0g_VKPDCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_corpus(target):\n",
        "    corpus=[]\n",
        "    \n",
        "    for x in tweet[tweet['Sub-task B']==target]['Text'].str.split():\n",
        "        for i in x:\n",
        "            corpus.append(i)\n",
        "    return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzUu0KgqP8Xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_corpus_df(tweet, target):\n",
        "    corpus=[]\n",
        "    \n",
        "    for x in tweet[tweet['Sub-task B']==target]['Text'].str.split():\n",
        "        for i in x:\n",
        "            corpus.append(i)\n",
        "    return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3oRHDcIQTU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus=create_corpus(0)\n",
        "\n",
        "dic=defaultdict(int)\n",
        "for word in corpus:\n",
        "    if word in stop:\n",
        "        dic[word]+=1\n",
        "        \n",
        "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYDy8YBKQXkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(stop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTBV3ohfQbii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (18.0, 6.0)\n",
        "x,y=zip(*top)\n",
        "plt.bar(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVKunR2sQenL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus=create_corpus(1)\n",
        "\n",
        "dic=defaultdict(int)\n",
        "for word in corpus:\n",
        "    if word in stop:\n",
        "        dic[word]+=1\n",
        "\n",
        "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
        "    \n",
        "\n",
        "plt.rcParams['figure.figsize'] = (18.0, 6.0)\n",
        "x,y=zip(*top)\n",
        "plt.bar(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk308k13Sf_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16,5))\n",
        "corpus=create_corpus(1)\n",
        "\n",
        "dic=defaultdict(int)\n",
        "special = string.punctuation\n",
        "for i in (corpus):\n",
        "    if i in special:\n",
        "        dic[i]+=1\n",
        "        \n",
        "x,y=zip(*dic.items())\n",
        "plt.bar(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxjI8cSLSkFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16,5))\n",
        "corpus=create_corpus(0)\n",
        "dic=defaultdict(int)\n",
        "special = string.punctuation\n",
        "for i in (corpus):\n",
        "    if i in special:\n",
        "        dic[i]+=1\n",
        "        \n",
        "x,y=zip(*dic.items())\n",
        "plt.bar(x,y,color='green')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgLhB4cESn7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter=Counter(corpus)\n",
        "most=counter.most_common()\n",
        "x=[]\n",
        "y=[]\n",
        "for word,count in most[:40]:\n",
        "    if (word not in stop) :\n",
        "        x.append(word)\n",
        "        y.append(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwbW0XIsSsRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.barplot(x=y,y=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sze9yWFPSv-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_tweet_bigrams(corpus, n=None):\n",
        "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ojXbvjSz9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16,5))\n",
        "top_tweet_bigrams=get_top_tweet_bigrams(tweet['Text'])[:10]\n",
        "x,y=map(list,zip(*top_tweet_bigrams))\n",
        "sns.barplot(x=y,y=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Vf2JlXS316",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.concat([tweet,test])\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gXlIyChS7MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example=\"New competition launched :https://www.kaggle.com/c/nlp-getting-started\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk6FHR90TCPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'',text)\n",
        "\n",
        "remove_URL(example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLhFInlCTDAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Text']=df['Text'].apply(lambda x : remove_URL(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-eB8oJYTRNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = \"\"\"<div>\n",
        "<h1>Real or Fake</h1>\n",
        "<p>Kaggle </p>\n",
        "<a href=\"https://www.kaggle.com/c/nlp-getting-started\">getting started</a>\n",
        "</div>\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6y7iVpzTULn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_html(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "print(remove_html(example))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDBh-O2NTXuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Text']=df['Text'].apply(lambda x : remove_html(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEekqJauTdp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FLAGS = re .MULTILINE | re .DOTALL \n",
        "def tokenize ( text ): # Different regex parts for smiley faces \n",
        "  eyes = r\"[8:=;]\" \n",
        "  nose = r\"[’‘\\−]?\" \n",
        "  # function \n",
        "  def re_sub ( pattern , repl ): \n",
        "    return re.sub( pattern , repl , text , flags=FLAGS) \n",
        "  text = re_sub(r\" https ?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S∗\" , \" url \") \n",
        "  # Smile −− :) , : ) , :−), (: , ( : , (−:, : ’) \n",
        "  text = re_sub(r\"(:\\s ?\\)|: −\\)|\\(\\s ?:|\\( −:|:\\ ’\\))\" , \" em_smile \") \n",
        "  # Laugh −− :D, : D, :−D, xD, x−D, XD, X−D \n",
        "  text = re_sub(r\"(:\\s?D|:−D|x−?D|X−?D)\" , \" em_laugh \") \n",
        "  # Love −− <3, :∗ \n",
        "  text = re_sub(r\"( <3|:.)\" , \" em_love \") \n",
        "  # Wink −− ;−), ;) , ;−D, ;D, (; , (−; \n",
        "  text = re_sub(r\"(;−?\\)|;−?D|\\(−?;)\" , \" em_wink \") \n",
        "  # Sad −− :−(, : ( , :( , ): , )−: \n",
        "  text = re_sub(r\"(:\\ s ?\\(|: −\\(|\\)\\s ?:|\\) −:)\" , \" em_sad \") \n",
        "  # Cry −− : ,( , : ’( , :\"( \n",
        "  text = re_sub(r\"(: ,\\(|:\\ ’\\(|:”\\()\" , \" em_cry \")\n",
        "  # remove funnnnny −−> funny \n",
        "  text = re_sub(r\"(.)\\1+\" , r\"\\1\\1\") \n",
        "  # remove & \n",
        "  text = re_sub(r\"(−|\\’)\" , \"\") \n",
        "  text = re_sub(r\"@[0−9]+−\", \" number \") \n",
        "  text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\". format (eyes , nose , nose , eyes ) , \" em_positive \") \n",
        "  text = re_sub(r\"{}{}p+\". format (eyes , nose ) , \" em_positive \") \n",
        "  text = re_sub(r\"{}{}\\(+|\\)+{}{}\". format (eyes , nose , nose , eyes ) , \" em_negative \") \n",
        "  text = re_sub(r\"{}{}[\\/| l ∗]\". format (eyes , nose ) , \" em_neutralface \") \n",
        "  text = re_sub(r\"−\", r\" \" ) \n",
        "  text = re_sub(r\"([ pls?s ]){2 ,}\" , r\"\\1\") \n",
        "  text = re_sub(r\"([ plz?z]){2 ,}\" , r\"\\1\") \n",
        "  text = re_sub(r\"\\\\n\" , r\" \") \n",
        "  text = re_sub(r\" sx \" ,\" sex \") \n",
        "  text = re_sub(r\" u \" ,\" you \") \n",
        "  text = re_sub(r\" r \" ,\" are \") \n",
        "  text = re_sub(r\" y \" ,\" why \") \n",
        "  text = re_sub(r\" Y \" ,\" WHY \") \n",
        "  text = re_sub(r\"Y \" ,\" WHY \") \n",
        "  text = re_sub(r\" hv \" ,\" have \") \n",
        "  text = re_sub(r\" c \" ,\" see \") \n",
        "  text = re_sub(r\" bcz \" ,\" because \")\n",
        "  text = re_sub(r\" coz \" ,\" because \") \n",
        "  text = re_sub(r\" v \" ,\" we \") \n",
        "  text = re_sub(r\" ppl \" ,\" people \") \n",
        "  text = re_sub(r\" pepl \" ,\" people \") \n",
        "  text = re_sub(r\" r b i \" ,\" rbi \") \n",
        "  text = re_sub(r\" R B I \" ,\" RBI \") \n",
        "  text = re_sub(r\" R b i \" ,\" rbi \") \n",
        "  text = re_sub(r\" R \" ,\" ARE \") \n",
        "  text = re_sub(r\" hav \" ,\" have \") \n",
        "  text = re_sub(r\"R \" ,\" ARE \") \n",
        "  text = re_sub(r\" U \" ,\" you \") \n",
        "  text = re_sub(r\"U \" ,\" you \") \n",
        "  text = re_sub(r\" pls \" ,\" please \") \n",
        "  text = re_sub(r\"Pls \" ,\" Please \") \n",
        "  text = re_sub(r\"plz \" ,\" please \") \n",
        "  text = re_sub(r\"Plz \" ,\" Please \") \n",
        "  text = re_sub(r\"PLZ \" ,\" Please \") \n",
        "  text = re_sub(r\"Pls \" ,\" Please \") \n",
        "  text = re_sub(r\"plz \" ,\" please \") \n",
        "  text = re_sub(r\"Plz \" ,\" Please \") \n",
        "  text = re_sub(r\"PLZ\" ,\" Please \") \n",
        "  text = re_sub(r\" thankz \" ,\" thanks \") \n",
        "  text = re_sub(r\" thnx \" ,\" thanks \") \n",
        "  text = re_sub(r\"fuck\\w+ \" ,\" fuck \") \n",
        "  text = re_sub(r\"f.. \" ,\" fuck \") \n",
        "  text = re_sub(r\"...k \" ,\" fuck \") \n",
        "  text = re_sub(r\"F.. \" ,\" fuck \") \n",
        "  text = re_sub(r\"mo..... \" ,\" fucker \") \n",
        "  text = re_sub(r\"b.... \" ,\" blody \") \n",
        "  text = re_sub(r\" mc \" ,\" fucker \") \n",
        "  text = re_sub(r\" MC \" ,\" fucker \") \n",
        "  text = re_sub(r\" wtf \" ,\" fuck \") \n",
        "  text = re_sub(r\" ch.t+i*[iy]a \" ,\" fucker \") \n",
        "  # text = re_sub(r\" ch.tya \" ,\" fucker \") \n",
        "  # text = re_sub(r\" ch..tia \" ,\" fucker \") \n",
        "  text = re_sub(r\" C...yas \" ,\" fucker \") \n",
        "  text = re_sub(r\"l.... \" ,\" shit \") \n",
        "  text = re_sub(r\" As+....S\" ,\" ASSHOLES\") \n",
        "  text = re_sub(r\" di....s\" ,\" fucker \") \n",
        "  text = re_sub(r\" nd \" ,\" and \") \n",
        "  text = re_sub(r\"Nd \" ,\"and \") \n",
        "  text = re_sub(r\"( ind [vs]pak )\" , \" india versus pakistan \") \n",
        "  text = re_sub(r\"(pak[vs] ind )\" , \" pakistan versus india \") \n",
        "  text = re_sub(r\"( indvsuae )\" , \" india versus United Arab Emirates \") \n",
        "  text = re_sub(r\"[sS] hut [Dd]own[jnuJNU]\" , \" shut down jnu \") \n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alpAFG3kTiwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Text'] = df['Text'].apply(tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mUBtQa0TorN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCqhniPlTsS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install emoji --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgrMRRUaTw5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import emoji\n",
        "def demojize(text):\n",
        "  return emoji.demojize(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nXv80EjT2g8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvqGCAugT6te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punct(text):\n",
        "    table=str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "    return text.translate(table)\n",
        "\n",
        "example=\"I am a #king\"\n",
        "print(remove_punct(example))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9rxWGH9T-t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Text']=df['Text'].apply(lambda x : remove_punct(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OrqZ2CFUERZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Text'] = df['Text'].apply(demojize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNgTT_UqUH2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_new1=create_corpus_df(df,1)\n",
        "len(corpus_new1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyCwjSwVUKei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_new1[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O98hwIoWUNO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating the wordcloud with the values under the category dataframe\n",
        "plt.figure(figsize=(12,8))\n",
        "word_cloud = WordCloud(\n",
        "                          background_color='black',\n",
        "                          max_font_size = 80\n",
        "                         ).generate(\" \".join(corpus_new1[:50]))\n",
        "plt.imshow(word_cloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH7ku8hMUQeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_new0=create_corpus_df(df,0)\n",
        "len(corpus_new0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950JhNs7UVhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_new0[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmYmZqCMUYl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating the wordcloud with the values under the category dataframe\n",
        "plt.figure(figsize=(12,8))\n",
        "word_cloud = WordCloud(\n",
        "                          background_color='black',\n",
        "                          max_font_size = 80\n",
        "                         ).generate(\" \".join(corpus_new0[:50]))\n",
        "plt.imshow(word_cloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KudzcKX4UceU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD_e3AD2Ujoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cv(data):\n",
        "    count_vectorizer = CountVectorizer()\n",
        "\n",
        "    emb = count_vectorizer.fit_transform(data)\n",
        "\n",
        "    return emb, count_vectorizer\n",
        "\n",
        "list_corpus = df[\"Text\"].tolist()\n",
        "list_labels = df[\"Sub-task B\"].tolist()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.2, \n",
        "                                                                                random_state=40)\n",
        "\n",
        "X_train_counts, count_vectorizer = cv(X_train)\n",
        "X_test_counts = count_vectorizer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ZpRTJlUwMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_LSA(test_data, test_labels, savepath=\"PCA_demo.csv\", plot=True):\n",
        "        lsa = TruncatedSVD(n_components=2)\n",
        "        lsa.fit(test_data)\n",
        "        lsa_scores = lsa.transform(test_data)\n",
        "        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n",
        "        color_column = [color_mapper[label] for label in test_labels]\n",
        "        colors = ['yellow','red']\n",
        "        if plot:\n",
        "            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n",
        "            orange_patch = mpatches.Patch(color='yellow', label='Not')\n",
        "            blue_patch = mpatches.Patch(color='red', label='Miso')\n",
        "            plt.legend(handles=[orange_patch, blue_patch], prop={'size': 30})\n",
        "\n",
        "fig = plt.figure(figsize=(16, 16))          \n",
        "plot_LSA(X_train_counts, y_train)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgNlsdEVUzpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf(data):\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    train = tfidf_vectorizer.fit_transform(data)\n",
        "\n",
        "    return train, tfidf_vectorizer\n",
        "\n",
        "X_train_tfidf, tfidf_vectorizer = tfidf(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdVj_QHOWH6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_LSA(X_train_tfidf, y_train)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxbH9nm8WxOH",
        "colab_type": "text"
      },
      "source": [
        "PRE-PROCESSING OF DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37Rs7_oedMnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUCjCw7-WPua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('/gdrive/My Drive/eng/eng/trac2_eng_train.csv')\n",
        "test_data = pd.read_csv('/gdrive/My Drive/trac2_eng_dev.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGdnYoi_cHto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['Text']=train_data['Text'].str.lower()\n",
        "train_data['Text']=train_data['Text'].apply(lambda x : remove_URL(x))\n",
        "train_data['Text']=train_data['Text'].apply(lambda x : remove_html(x))\n",
        "train_data['Text']=train_data['Text'].apply(lambda x : tokenize(x))\n",
        "train_data['Text']=train_data['Text'].apply(lambda x : demojize(x))\n",
        "train_data['Text']=train_data['Text'].apply(lambda x : remove_punct(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_11mCi5M4sV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v49IjBzZ5HHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pyspellchecker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1W0v9HjBLnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.drop(['Sub-task A'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLxWzPJvCVFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data[\"Sub-task B\"] = train_data[\"Sub-task B\"].map({\"GEN\": 1, \"NGEN\": 0})\n",
        "test_data[\"Sub-task B\"] = test_data[\"Sub-task B\"].map({\"GEN\": 1, \"NGEN\": 0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYkx4TrCCbxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcZg2ZL9CwwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7i-28ZwQxR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ros = RandomOverSampler(random_state=777)\n",
        "train_data['Text'], train_data['Sub-task B'] = ros.fit_resample(train_data['Text'], train_data['Sub-task B'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAHabBYaXrK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords') \n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWdReqKGXtXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stopwords(text):\n",
        "      return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNlJibn1XwvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data[\"Text\"] = train_data[\"Text\"].apply(stopwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QZadWFyYvlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "cnt = Counter()\n",
        "for text in train_data[\"Text\"].values:\n",
        "    for word in text.split():\n",
        "        cnt[word] +=1\n",
        "        \n",
        "cnt.most_common(50) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ-BM60vYwvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq = set([w for (w, wc) in cnt.most_common(10)])\n",
        "def freqwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not \n",
        "in freq])\n",
        "train_data[\"Text\"] = train_data[\"Text\"].apply(freqwords)\n",
        "train_data[\"Text\"].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oss7lIvh2HqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data['Text']=test_data['Text'].str.lower()\n",
        "test_data['Text']=test_data['Text'].apply(lambda x : remove_URL(x))\n",
        "test_data['Text']=test_data['Text'].apply(lambda x : remove_html(x))\n",
        "test_data['Text']=test_data['Text'].apply(lambda x : tokenize(x))\n",
        "test_data['Text']=test_data['Text'].apply(lambda x : demojize(x))\n",
        "test_data['Text']=test_data['Text'].apply(lambda x : remove_punct(x))\n",
        "test_data[\"Text\"] = test_data[\"Text\"].apply(stopwords)\n",
        "test_data[\"Text\"] = test_data[\"Text\"].apply(freqwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBU0y4qlQlqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pGSFEJ-_9WO",
        "colab_type": "text"
      },
      "source": [
        "BERT IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qxx7p057Cy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsiofyWuAQg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install fastai"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssdw67IvAeW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KhFd1dfAoz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv1s8rNTA5gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai\n",
        "import transformers\n",
        "print('fastai version :', fastai.__version__)\n",
        "print('transformers version :', transformers.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EwG4irMDeIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-R2hTEsCfTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n",
        "model_type = 'bert'\n",
        "pretrained_model_name='bert-base-uncased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hPu4lT7DKVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Zf6ysLDRgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class.pretrained_model_archive_map.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qripWnd-DUCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qdboxu7DnK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtbkaJ8vDpob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "            tokens = [CLS] + tokens + [SEP]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "            if self.model_type in ['xlnet']:\n",
        "                tokens = tokens + [SEP] +  [CLS]\n",
        "            else:\n",
        "                tokens = [CLS] + tokens + [SEP]\n",
        "        return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjgkTKJcDsiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0E7BZhQDxDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "    \n",
        "    def __getstate__(self):\n",
        "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "    def __setstate__(self, state:dict):\n",
        "        self.itos = state['itos']\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BolUFqNvD0yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwySzVEnD3dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_first = bool(model_type in ['bert'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g2DjHr_D64v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
        "print(tokens)\n",
        "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)\n",
        "transformer_tokenizer.convert_ids_to_tokens(ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RCO6ITvD9KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "databunch = (TextList.from_df(train_data, cols='Text', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'Sub-task B')\n",
        "             .add_test(test_data)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufEMSeu8D_-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "databunch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcwrPJYgENbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n",
        "test_one_batch = databunch.one_batch()[0]\n",
        "print('Batch shape : ',test_one_batch.shape)\n",
        "print(test_one_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qfy84j3GG3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining our model architecture \n",
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK9kgLt8OIFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = 5\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8puF5obOONDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvjh_gNoOQIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate, FBeta(beta=1, average='macro')])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Seems to not working\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-Fi644TOVxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(learner.model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEee-gT7OZcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_layers = [learner.model.transformer.bert.embeddings,\n",
        "              learner.model.transformer.bert.encoder.layer[0],\n",
        "              learner.model.transformer.bert.encoder.layer[1],\n",
        "              learner.model.transformer.bert.encoder.layer[2],\n",
        "              learner.model.transformer.bert.encoder.layer[3],\n",
        "              learner.model.transformer.bert.encoder.layer[4],\n",
        "              learner.model.transformer.bert.encoder.layer[5],\n",
        "              learner.model.transformer.bert.encoder.layer[6],\n",
        "              learner.model.transformer.bert.encoder.layer[7],\n",
        "              learner.model.transformer.bert.encoder.layer[8],\n",
        "              learner.model.transformer.bert.encoder.layer[9],\n",
        "              learner.model.transformer.bert.encoder.layer[10],\n",
        "              learner.model.transformer.bert.encoder.layer[11],\n",
        "              learner.model.transformer.bert.pooler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4qONTq6Oe_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.split(list_layers)\n",
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')\n",
        "print(learner.layer_groups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnlBiXnDOjyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.model_dir='/gdrive/My Drive/eng/eng/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VU6-F2ROnkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('untrain_bert')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTxt48pTOqH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('untrain_bert');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTaA4v0mOsZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwr0KoQoOu4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmRR6ymlOxHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuGUKDmjO1YG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.recorder.plot(skip_end=10,suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnV1v-a0O8gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle(10,max_lr=1e-03,moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXuA2DhiO9qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('first_cycle_bert')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgoZ99wqPAmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('first_cycle_bert');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDZmzUF7PDQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibhpy62hPG7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 6e-05"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGN7150IPDWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle(10, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8FyYiRmPZix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('second_cycle_bert')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJTiL_BLPch_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('second_cycle_bert');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLTTAzt_PgR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN2cWj54PjGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle(10, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJo_9S7VPmTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('third_cycle_bert')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpcTfRNIPplH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('third_cycle_bert');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0HNeRnUPtTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.predict('This is the best movie of 2020')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFhjVv2HPwcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.predict('such a bitch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7e_CKgRPzOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.predict('make me a sandwich good for nothing woman')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoCjVNy9P30g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZpEV-KLP4H4",
        "colab_type": "text"
      },
      "source": [
        "LINEAR MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKGLT1F_QUAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df5 = train_data[['Sub-task B']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG7VeXSmdY3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "df55 = df5.apply(le.fit_transform)\n",
        "df55.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZUa9dIVdgI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = preprocessing.OneHotEncoder()\n",
        "enc.fit(df55)\n",
        "onehotlabels2 = enc.transform(df55).toarray()\n",
        "onehotlabels2.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfoV_rXhdkgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onehotlabels2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6O9Avuodopj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df555 = pd.DataFrame(onehotlabels2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkHQR7FYdsk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df555.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l163b4mydvMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = train_data['Text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElCPbAzYd28u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df22 = np.array(df2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsG8sR27d6-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(df22, df55['Sub-task B'], random_state = 42)\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "X_test_counts = count_vect.transform(X_test)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6bcH9wjd-s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "models = [\n",
        "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
        "    LinearSVC(),\n",
        "    MultinomialNB(),\n",
        "    LogisticRegression(random_state=0),\n",
        "]\n",
        "CV = 5\n",
        "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
        "entries = []\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_val_score(models, labels, scoring='accuracy', cv=CV)\n",
        "  for fold_idx, accuracy in enumerate(accuracies):\n",
        "    entries.append((model_name, fold_idx, accuracy))\n",
        "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
        "import seaborn as sns\n",
        "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
        "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
        "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4ruIusOeV-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model_ug_cbow = KeyedVectors.load('w2v_model_ug_cbow.word2vec')\n",
        "model_ug_sg = KeyedVectors.load('w2v_model_ug_sg.word2vec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrx4xYaReZ7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install word2vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDREgISweey6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb = MultinomialNB()\n",
        "y_score=nb.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY7Ca2QCevPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = nb.predict(X_test_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M1Hgvp_ev9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb.score(y_pred,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue62FeN2ezbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(df22, df55['Sub-task B'], random_state = 0)\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "X_test_counts = count_vect.transform(X_test)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
        "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQnEBFdUe4cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb = MultinomialNB()\n",
        "y_score=nb.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-PCOTgEe7so",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.score(y_test,y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNoaeHmye-CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVyBZHlSfByb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(df22, df55['Sub-task B'], random_state = 0)\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "X_test_counts = count_vect.transform(X_test)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
        "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXXg07mMfFOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb = MultinomialNB()\n",
        "y_score=nb.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbBUBhvgfH5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sMvQp-TfSSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "score = classifier.score(X_test_tfidf, y_test)\n",
        "\n",
        "print(\"Accuracy:\", score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMhaZZCmfVCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "score = classifier.score(X_test_tfidf, y_test)\n",
        "print('Accuracy for {} data: {:.4f}'.format(source, score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A63LLi3rfXdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = X_train_tfidf.shape[1]  \n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsRJo8z0fbMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdAcat2lfd9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history1 = model.fit(X_train_tfidf, y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=True,\n",
        "                    validation_data=(X_test_tfidf, y_test),\n",
        "                    batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJkF7bIMfhk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_score(y_test, y_pred1, average=\"macro\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq5f01Z3fkz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_tweet_texts = []\n",
        "for i in range(nums[0],nums[1]):\n",
        "    clean_tweet_texts.append(tweet_cleaner(train['Text'][i]))\n",
        "nums = [0,len(test)]\n",
        "test_tweet_texts = []\n",
        "for i in range(nums[0],nums[1]):\n",
        "    test_tweet_texts.append(tweet_cleaner(test['Text'][i])) \n",
        "train_clean = pd.DataFrame(clean_tweet_texts,columns=['Text'])\n",
        "train_clean['label'] = train['Sub-task B']\n",
        "train_clean['ID'] = train.ID\n",
        "test_clean = pd.DataFrame(test_tweet_texts,columns=[['Text', 'Sub-task B']])\n",
        "test_clean['ID'] = test.ID"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyuEhcO8gkCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train_clean['Text'],train_clean['label'])\n",
        "train_x = train_clean['Text']\n",
        "valid_x = test_clean['Text']\n",
        "train_y = train_clean['label']\n",
        "valid_y = test_clean['Sub-task B']\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMRXaaFuglUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
        "tfidf_vect.fit(train_clean['Text'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJzWHd17gyVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    return metrics.f1_score(valid_y,predictions,average='macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvlavePYg2Hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracyORIGINAL = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
        "accuracyORIGINAL = train_model(svm.LinearSVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print (\"SVM Baseline, WordLevel TFIDF: \", accuracyORIGINAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hivHMIqcg9TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ros = RandomOverSampler(random_state=777)\n",
        "ros_xtrain_tfidf, ros_train_y = ros.fit_sample(xtrain_tfidf, train_y)\n",
        "accuracyROS = train_model(linear_model.LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),ros_xtrain_tfidf, ros_train_y, xvalid_tfidf)\n",
        "print (\"LR ORIGINAL, WordLevel TFIDF: \", accuracyROS)\n",
        "accuracyROS = train_model(svm.LinearSVC(),ros_xtrain_tfidf, ros_train_y, xvalid_tfidf)\n",
        "print (\"SVM ROS, WordLevel TFIDF: \", accuracyROS)\n",
        "accuracyROS = train_model(linear_model.SGDClassifier(loss='hinge'),ros_xtrain_tfidf, ros_train_y, xvalid_tfidf)\n",
        "print (\"SGDClassifier, WordLevel TFIDF: \", accuracyROS)\n",
        "accuracyROS = train_model(linear_model.RidgeClassifier(alpha=5.0),ros_xtrain_tfidf, ros_train_y, xvalid_tfidf)\n",
        "print (\"SGDClassifier, WordLevel TFIDF: \", accuracyROS)\n",
        "accuracyROS = train_model(linear_model.LogisticRegressionCV(Cs=10),ros_xtrain_tfidf, ros_train_y, xvalid_tfidf)\n",
        "print (\"SGDClassifier, WordLevel TFIDF: \", accuracyROS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQR1iAEphE_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}